{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e83296f",
   "metadata": {},
   "source": [
    "## 1. C√≥digo de scraping para o estat√≠sticas dos jogadores no FBREF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e69229f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Iniciando captura da liga: Venezuelan-Primera-Division (ID: 105)\n",
      "  -> Coletando stats...\n",
      "  -> Coletando shooting...\n",
      "  -> Coletando passing...\n",
      "  -> Coletando passing_types...\n",
      "  -> Coletando gca...\n",
      "  -> Coletando defense...\n",
      "  -> Coletando possession...\n",
      "  -> Coletando playingtime...\n",
      "  -> Coletando misc...\n",
      "  -> Coletando keepers...\n",
      "  -> Coletando keepersadv...\n",
      "\n",
      "‚úÖ SUCESSO! Dados de 'Venezuelan-Primera-Division' salvos na tabela 'venezuelan_primera_division_consolidado'.\n",
      "üìä Total de jogadores: 494\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import cloudscraper\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "from io import StringIO\n",
    "import re\n",
    "\n",
    "def extrair_tabela_real_fbref(url):\n",
    "    scraper = cloudscraper.create_scraper()\n",
    "    try:\n",
    "        response = scraper.get(url)\n",
    "        if response.status_code != 200: return None\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        comentarios = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "        html_completo = response.text + \"\".join([str(com) for com in comentarios])\n",
    "        \n",
    "        tabelas = pd.read_html(StringIO(html_completo))\n",
    "        for df in tabelas:\n",
    "            cols = df.columns.get_level_values(-1) if isinstance(df.columns, pd.MultiIndex) else df.columns\n",
    "            if 'Player' in cols:\n",
    "                if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.droplevel(0)\n",
    "                df = df[df['Player'] != 'Player'].copy()\n",
    "                return df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    except:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def scraper_fbref_liga_unica(url_base):\n",
    "    # 1. Identificar ID e Nome da liga pela URL informada\n",
    "    # Exemplo: https://fbref.com/en/comps/13/stats/Serie-A-Stats -> ID: 13, Nome: Serie-A\n",
    "    match = re.search(r'comps/(\\d+)/stats/(.+)-Stats', url_base)\n",
    "    \n",
    "    if not match:\n",
    "        print(\"‚ùå Erro: O link fornecido n√£o parece ser o link de 'Stats' (Standard) do FBRef.\")\n",
    "        return\n",
    "\n",
    "    id_liga = match.group(1)\n",
    "    nome_liga = match.group(2)\n",
    "    \n",
    "    categorias_slugs = [\n",
    "        \"stats\", \"shooting\", \"passing\", \"passing_types\", \"gca\", \n",
    "        \"defense\", \"possession\", \"playingtime\", \"misc\", \"keepers\", \"keepersadv\"\n",
    "    ]\n",
    "    \n",
    "    df_liga_completa = None\n",
    "    conn = sqlite3.connect('scouting_sulamerica.db')\n",
    "\n",
    "    # 2. Loop pelas categorias\n",
    "    for cat in categorias_slugs:\n",
    "        url_cat = f\"https://fbref.com/en/comps/{id_liga}/{cat}/{nome_liga}-Stats\"\n",
    "        print(f\"  -> Coletando {cat}...\")\n",
    "        \n",
    "        df_temp = extrair_tabela_real_fbref(url_cat)\n",
    "        \n",
    "        if df_temp is not None:\n",
    "            if df_liga_completa is None:\n",
    "                df_liga_completa = df_temp\n",
    "            else:\n",
    "                cols_to_use = df_temp.columns.difference(df_liga_completa.columns).tolist()\n",
    "                cols_to_use.extend(['Player', 'Squad'])\n",
    "                df_liga_completa = pd.merge(df_liga_completa, df_temp[cols_to_use], on=['Player', 'Squad'], how='left')\n",
    "                # Remove duplicatas de colunas que podem surgir no merge\n",
    "                df_liga_completa = df_liga_completa.loc[:, ~df_liga_completa.columns.duplicated()].copy()\n",
    "        \n",
    "        # Respeita o servidor para n√£o ser banido\n",
    "        time.sleep(12) \n",
    "\n",
    "    # 3. Finaliza√ß√£o e Salvamento\n",
    "    if df_liga_completa is not None:\n",
    "        df_liga_completa['League'] = nome_liga\n",
    "        df_liga_completa['Data_Analise'] = datetime.now().strftime(\"%d/%m/%Y\")\n",
    "        \n",
    "        # Limpa nomes de colunas para o SQL\n",
    "        df_liga_completa.columns = [str(c).replace('/', '_per_').replace('.', '_').replace(' ', '_') for c in df_liga_completa.columns]\n",
    "        \n",
    "        # Nome da tabela din√¢mico (ex: serie_b_player_stats)\n",
    "        tabela_nome = f\"{nome_liga.lower().replace('-', '_')}_player_stats\"\n",
    "        \n",
    "        df_liga_completa.to_sql(tabela_nome, conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "        \n",
    "        print(f\"\\n SUCESSO! Dados de '{nome_liga}' salvos na tabela '{tabela_nome}'.\")\n",
    "        print(f\"Total de jogadores: {len(df_liga_completa)}\")\n",
    "    else:\n",
    "        print(\" Falha cr√≠tica: Nenhum dado p√¥de ser coletado.\")\n",
    "\n",
    "# --- MODO DE USO ---\n",
    "# Basta trocar este link pela liga que voc√™ quer:\n",
    "link_da_vez = \"https://fbref.com/en/comps/105/stats/Venezuelan-Primera-Division-Stats\" \n",
    "\n",
    "scraper_fbref_liga_unica(link_da_vez)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7b8ddb",
   "metadata": {},
   "source": [
    "## 2. C√≥digo de scraping para perfil dos jogadores (altura e p√© de prefer√™ncia) no Transfermarkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0240757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando clubes da liga em: https://www.transfermarkt.com/liga-futve-clausura/startseite/wettbewerb/VZ1C\n",
      "Total de times encontrados: 14\n",
      "[1/14] Acessando: carabobo-fc\n",
      "[2/14] Acessando: deportivo-la-guaira\n",
      "[3/14] Acessando: monagas-sc\n",
      "[4/14] Acessando: universidad-central-de-venezuela\n",
      "[5/14] Acessando: academia-puerto-cabello\n",
      "[6/14] Acessando: caracas-fc\n",
      "[7/14] Acessando: deportivo-tachira\n",
      "[8/14] Acessando: academia-anzoategui-fc\n",
      "[9/14] Acessando: metropolitanos-fc\n",
      "[10/14] Acessando: zamora-fc\n",
      "[11/14] Acessando: portuguesa-fc\n",
      "[12/14] Acessando: estudiantes-de-merida\n",
      "[13/14] Acessando: yaracuyanos-futbol-club\n",
      "[14/14] Acessando: dvo-rayo-zuliano\n",
      "\n",
      "‚ú® Sucesso! Tabela 'liga_futve_clausura_perfil' criada com 407 jogadores.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cloudscraper\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import time\n",
    "import sqlite3\n",
    "import re\n",
    "\n",
    "def extrair_links_times_automatico(url_liga):\n",
    "    \"\"\"Descobre os links dos times de qualquer liga fornecida.\"\"\"\n",
    "    scraper = cloudscraper.create_scraper()\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}\n",
    "    \n",
    "    print(f\"Buscando clubes da liga em: {url_liga}\")\n",
    "    response = scraper.get(url_liga, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    links_detalhados = []\n",
    "    tabela = soup.find(\"table\", {\"class\": \"items\"})\n",
    "    \n",
    "    if not tabela:\n",
    "        print(\"Erro: Tabela de times n√£o encontrada. Verifique se o link est√° correto.\")\n",
    "        return []\n",
    "\n",
    "    for link in tabela.find_all('a', href=True):\n",
    "        href = link['href']\n",
    "        # Captura o padr√£o de link de time\n",
    "        if '/startseite/verein/' in href:\n",
    "            match = re.search(r'/(.+?)/startseite/verein/(\\.?\\d+)', href)\n",
    "            if match:\n",
    "                nome_slug = match.group(1)\n",
    "                id_time = match.group(2)\n",
    "                # URL detalhada (Kader + plus/1) para pegar Altura e P√©\n",
    "                url_formatada = f\"https://www.transfermarkt.com/{nome_slug}/kader/verein/{id_time}/plus/1\"\n",
    "                \n",
    "                if url_formatada not in links_detalhados:\n",
    "                    links_detalhados.append(url_formatada)\n",
    "            \n",
    "    return links_detalhados\n",
    "\n",
    "def limpar_transfermarkt_detalhado(df):\n",
    "    mapping = {\n",
    "        'Player': [col for col in df.columns if 'Player' in col or 'Name' in col],\n",
    "        'Height': [col for col in df.columns if 'Height' in col],\n",
    "        'Foot': [col for col in df.columns if 'Foot' in col],\n",
    "        'Value': [col for col in df.columns if 'Value' in col or 'Market' in col]\n",
    "    }\n",
    "\n",
    "    colunas_encontradas = {chave: lista[0] for chave, lista in mapping.items() if lista}\n",
    "    df_limpo = df[list(colunas_encontradas.values())].copy()\n",
    "    df_limpo.columns = list(colunas_encontradas.keys())\n",
    "\n",
    "    # Remove as linhas de r√≥tulo (Goalkeeper, Left, etc) que n√£o t√™m altura\n",
    "    if 'Height' in df_limpo.columns:\n",
    "        df_limpo = df_limpo.dropna(subset=['Height'])\n",
    "\n",
    "    # Limpeza de nomes (remove a posi√ß√£o que o TM gruda no texto)\n",
    "    cargos = ['Goalkeeper', 'Centre-Back', 'Left-Back', 'Right-Back', 'Defensive Midfield', \n",
    "              'Central Midfield', 'Attacking Midfield', 'Left Winger', 'Right Winger', \n",
    "              'Second Striker', 'Centre-Forward', 'Defender', 'Midfield', 'Forward']\n",
    "    \n",
    "    for cargo in cargos:\n",
    "        df_limpo['Player'] = df_limpo['Player'].str.replace(cargo, '', case=False).str.strip()\n",
    "\n",
    "    # Remove n√∫meros que ficam grudados no nome\n",
    "    df_limpo['Player'] = df_limpo['Player'].str.replace(r'\\d+', '', regex=True).str.strip()\n",
    "\n",
    "    return df_limpo\n",
    "\n",
    "def scraper_transfermarkt_automatico(url_liga_alvo):\n",
    "    \n",
    "    # 1. Identifica o nome da liga para salvar a tabela com nome correto\n",
    "    match_nome = re.search(r'com/(.+?)/startseite', url_liga_alvo)\n",
    "    nome_liga_limpo = match_nome.group(1).replace('-', '_') if match_nome else \"liga_generica\"\n",
    "    \n",
    "    links_times = extrair_links_times_automatico(url_liga_alvo)\n",
    "    print(f\"Total de times encontrados: {len(links_times)}\")\n",
    "    \n",
    "    scraper = cloudscraper.create_scraper()\n",
    "    todos_perfis = []\n",
    "\n",
    "    for i, url in enumerate(links_times):\n",
    "        nome_time_log = url.split('/')[3]\n",
    "        print(f\"[{i+1}/{len(links_times)}] Acessando: {nome_time_log}\")\n",
    "        \n",
    "        try:\n",
    "            response = scraper.get(url)\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                tabela_html = soup.find('table', {'class': 'items'})\n",
    "                \n",
    "                if tabela_html:\n",
    "                    df_raw = pd.read_html(StringIO(str(tabela_html)))[0]\n",
    "                    df_limpo = limpar_transfermarkt_detalhado(df_raw)\n",
    "                    df_limpo['Squad_TM'] = nome_time_log\n",
    "                    todos_perfis.append(df_limpo)\n",
    "            \n",
    "            # Delay de seguran√ßa obrigat√≥rio para o TM\n",
    "            time.sleep(15)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro em {nome_time_log}: {e}\")\n",
    "\n",
    "    if todos_perfis:\n",
    "        df_final = pd.concat(todos_perfis, ignore_index=True)\n",
    "        # Remove duplicatas finais por seguran√ßa\n",
    "        df_final = df_final.drop_duplicates(subset=['Player', 'Squad_TM'])\n",
    "        \n",
    "        conn = sqlite3.connect('scouting_sulamerica.db')\n",
    "        tabela_nome = f\"{nome_liga_limpo}_perfil\"\n",
    "        df_final.to_sql(tabela_nome, conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "        print(f\"\\n Sucesso! Tabela '{tabela_nome}' criada com {len(df_final)} jogadores.\")\n",
    "    else:\n",
    "        print(\"Nenhum dado coletado.\")\n",
    "\n",
    "# --- COMO USAR ---\n",
    "# Cole aqui o link 'Startseite' da liga que voc√™ quer\n",
    "link_liga = \"https://www.transfermarkt.com/liga-futve-clausura/startseite/wettbewerb/VZ1C\"\n",
    "\n",
    "scraper_transfermarkt_automatico(link_liga)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab3d450",
   "metadata": {},
   "source": [
    "## 3. C√≥digo para Normaliza√ß√£o, Limpeza dos dados e Gera√ß√£o da base de dados final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df36aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fus√£o Conclu√≠da: 472 jogadores √∫nicos.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "def normalizar_nome(nome):\n",
    "    if not nome: return \"\"\n",
    "    nome = ''.join(c for c in unicodedata.normalize('NFD', str(nome)) if unicodedata.category(c) != 'Mn')\n",
    "    return nome.lower().strip()\n",
    "\n",
    "def limpar_valor_monetario(valor):\n",
    "    if pd.isna(valor) or valor == '-' or valor == '': return 0.0\n",
    "    v = str(valor).replace('‚Ç¨', '').replace(' ', '').replace(',', '.')\n",
    "    try:\n",
    "        if 'm' in v: return float(v.replace('m', '')) * 1_000_000\n",
    "        if 'k' in v: return float(v.replace('k', '')) * 1_000\n",
    "        return float(v)\n",
    "    except: return 0.0\n",
    "\n",
    "def gerar_base_scouting_final_total():\n",
    "    conn = sqlite3.connect('scouting_sulamerica.db')\n",
    "    \n",
    "    # 1. Carregar Dados Brutos\n",
    "    df_stats = pd.read_sql(\"SELECT * FROM venezuelan_primera_division_consolidado\", conn) # Substitui com o nome da tabela de stats criado para determinada liga\n",
    "    df_perfil = pd.read_sql(\"SELECT * FROM liga_futve_clausura_perfil\", conn) # Substitui com o nome da tabela de perfil criado para determinada liga\n",
    "    \n",
    "    # 2. Preparar Chaves\n",
    "    df_stats['nome_busca'] = df_stats['Player'].apply(normalizar_nome)\n",
    "    df_stats['ID_FUSAO'] = df_stats['nome_busca'] + \"_\" + df_stats['Born'].astype(str) # Fus√£o dos jogadores por Nome + Ano de nascimento (foi utilizada como teste)\n",
    "\n",
    "    # 3. DICION√ÅRIO DE REGRAS\n",
    "    regras_agrupamento = {}\n",
    "    \n",
    "    # Lista do que NUNCA deve ser somado (Identifica√ß√£o)\n",
    "    cols_identificacao = ['Player', 'Nation', 'Pos', 'Squad', 'Born', 'Age', 'Data_Analise', 'nome_busca', 'ID_FUSAO']\n",
    "\n",
    "    for col in df_stats.columns:\n",
    "        # Se for coluna de texto ou idade/ano, mantemos o valor (last)\n",
    "        if col in cols_identificacao:\n",
    "            regras_agrupamento[col] = 'last'\n",
    "        else:\n",
    "            # Converte para n√∫mero para garantir o c√°lculo\n",
    "            df_stats[col] = pd.to_numeric(df_stats[col], errors='coerce')\n",
    "            \n",
    "            # Regra de M√©dia: tudo que tem '90', '%' ou 'per'\n",
    "            if any(x in col.lower() for x in ['90', '%', 'per']):\n",
    "                regras_agrupamento[col] = 'mean'\n",
    "            # Regra de Soma: Gols, Assist√™ncias, Minutos, Jogos\n",
    "            else:\n",
    "                regras_agrupamento[col] = 'sum'\n",
    "\n",
    "    # 4. Agrupar e Fundir \n",
    "    df_stats_agrupado = df_stats.groupby('ID_FUSAO').agg(regras_agrupamento).reset_index(drop=True)\n",
    "\n",
    "    # 5. Merge com Transfermarkt\n",
    "    df_perfil['nome_busca'] = df_perfil['Player'].apply(normalizar_nome)\n",
    "    df_perfil['Market_Value_Real'] = df_perfil['Value'].apply(limpar_valor_monetario)\n",
    "    \n",
    "    # Pega o melhor perfil do TM (com maior valor)\n",
    "    df_perfil_unique = df_perfil.sort_values(by=['nome_busca', 'Market_Value_Real'], ascending=[True, False]).drop_duplicates(subset=['nome_busca'])\n",
    "\n",
    "    df_final = pd.merge(\n",
    "        df_stats_agrupado, \n",
    "        df_perfil_unique[['nome_busca', 'Height', 'Foot', 'Value', 'Market_Value_Real']], \n",
    "        on='nome_busca', \n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # 6. Salvar e Printar\n",
    "    df_final = df_final.drop(columns=['nome_busca', 'ID_FUSAO'])\n",
    "    df_final.to_sql('base_scouting_venezuela', conn, if_exists='replace', index=False)\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"‚úÖ Fus√£o Conclu√≠da: {len(df_final)} jogadores √∫nicos.\")\n",
    "    return df_final\n",
    "\n",
    "# Chamada do script\n",
    "df_master = gerar_base_scouting_final_total()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56277e41",
   "metadata": {},
   "source": [
    "## 4. Limpeza Final da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746f9ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Master limpa e padronizada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "def limpar_base_master_definitiva(df):\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # 1. Limpeza da Altura (Ex: \"1,85m\" -> 1.85)\n",
    "    if 'Height' in df_clean.columns:\n",
    "        df_clean['Height'] = (\n",
    "            df_clean['Height']\n",
    "            .str.replace('m', '', regex=False)\n",
    "            .str.replace(',', '.', regex=False)\n",
    "            .replace('-', None) # Transforma h√≠fen em nulo real (NaN)\n",
    "        )\n",
    "        df_clean['Height'] = pd.to_numeric(df_clean['Height'], errors='coerce')\n",
    "\n",
    "    # 2. Limpeza do P√© Preferido\n",
    "    if 'Foot' in df_clean.columns:\n",
    "        # Padroniza: 'left', 'right', 'both' ou None\n",
    "        df_clean['Foot'] = df_clean['Foot'].replace('-', None).str.lower().str.strip()\n",
    "\n",
    "    # 3. Limpeza do Valor de Mercado (Garante que a coluna Real seja num√©rica)\n",
    "    if 'Market_Value_Real' in df_clean.columns:\n",
    "        df_clean['Market_Value_Real'] = pd.to_numeric(df_clean['Market_Value_Real'], errors='coerce').fillna(0)\n",
    "\n",
    "    # 4. Limpeza Geral de Estat√≠sticas de Performance\n",
    "    # Substitui NaNs por 0 em colunas que deveriam ser num√©ricas (Gols, Assist√™ncias, etc)\n",
    "    cols_stats = df_clean.select_dtypes(include=['number']).columns\n",
    "    df_clean[cols_stats] = df_clean[cols_stats].fillna(0)\n",
    "\n",
    "    # 5. Organiza√ß√£o de Colunas de Texto\n",
    "    # Garante que n√£o existam espa√ßos sobrando nos nomes e posi√ß√µes\n",
    "    for col in ['Player', 'Squad', 'Pos']:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = df_clean[col].astype(str).str.strip()\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "df_master = limpar_base_master_definitiva(df_master)\n",
    "\n",
    "conn = sqlite3.connect('scouting_sulamerica.db')\n",
    "df_master.to_sql('base_scouting_venezuela', conn, if_exists='replace', index=False) # Substituir o nome para a liga determinada\n",
    "conn.close()\n",
    "\n",
    "print(\"Base Master limpa e padronizada com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
